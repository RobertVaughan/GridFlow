{
  "id": "gridflow-ollama",
  "title": "GridFlow Ollama Pack",
  "version": "1.0.0",
  "language": "python",
  "entry": "runner.py",
  "timeoutSec": 60,
  "requirements": "requirements.txt",

  "assets": {
    "python": ["assets/python/utils.py"],
    "js": ["assets/js/ollama_ui.js"],
    "css": ["assets/css/ollama.css"]
  },

  "nodes": [
    {
      "type": "ollama.model",
      "title": "Ollama Model",
      "inputs": [
        { "id": "execIn", "name": "««", "direction": "in", "dataType": "exec" }
      ],
      "outputs": [
        { "id": "execOut", "name": "»»", "direction": "out", "dataType": "exec" },
        { "id": "model", "name": "Model", "direction": "out", "dataType": "string" }
      ],
      "ui": {
        "inspector": [
          { "key": "model", "label": "Model (name)", "type": "text" }
        ]
      },
      "description": "Select a model (or hard-type its name)."
    },

    {
      "type": "ollama.chat_input",
      "title": "Chat Input",
      "inputs": [
        { "id": "execIn", "name": "««", "direction": "in", "dataType": "exec" }
      ],
      "outputs": [
        { "id": "execOut", "name": "»»", "direction": "out", "dataType": "exec" },
        { "id": "message", "name": "Message", "direction": "out", "dataType": "string" }
      ],
      "ui": {
        "inspector": [
          { "key": "text", "label": "User Message", "type": "text" }
        ]
      },
      "description": "Provides a user message."
    },

    {
      "type": "ollama.dialog",
      "title": "Ollama Dialog",
      "inputs": [
        { "id": "execIn", "name": "««", "direction": "in", "dataType": "exec" },
        { "id": "user", "name": "User Message", "direction": "in", "dataType": "string" },
        { "id": "assistant", "name": "Assistant", "direction": "in", "dataType": "string" }
      ],
      "outputs": [
        { "id": "execOut", "name": "»»", "direction": "out", "dataType": "exec" },
        { "id": "html", "name": "HTML", "direction": "out", "dataType": "string" }
      ],
      "ui": { "inspector": [] },
      "description": "Formats a simple chat transcript as HTML."
    },

    {
      "type": "ollama.interpreter",
      "title": "Ollama Interpreter",
      "inputs": [
        { "id": "execIn", "name": "««", "direction": "in", "dataType": "exec" },
        { "id": "model", "name": "Model", "direction": "in", "dataType": "string" },
        { "id": "message", "name": "Message", "direction": "in", "dataType": "string" },
        { "id": "system", "name": "System", "direction": "in", "dataType": "string" }
      ],
      "outputs": [
        { "id": "execOut", "name": "»»", "direction": "out", "dataType": "exec" },
        { "id": "assistant", "name": "Assistant", "direction": "out", "dataType": "string" },
        { "id": "html", "name": "HTML", "direction": "out", "dataType": "string" }
      ],
      "ui": {
        "inspector": [
          { "key": "model", "label": "Default Model", "type": "text" },
          { "key": "system", "label": "System Prompt", "type": "text" }
        ]
      },
      "description": "Calls the local Ollama server and returns the answer + HTML."
    }
  ]
}
